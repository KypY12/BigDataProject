# Comenzi folosite pe instanta

start-all.sh
cd stacks
ls -al
arm-env.sh

jps

python3 --version
java -version
scala -version
pyspark --version

pyspark --packages graphframes:graphframes:0.8.2-spark3.2-s_2.12
ls -al /home/ubuntu/.ivy2/jars
cd /usr/local/spark/jars/
cp /home/ubuntu/.ivy2/jars/* .
ls -al

cd ~
ls -al
sudo nano ~/.profile

export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3.6
export PYSPARK_SUBMIT_ARGS="--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell"
export PYTHONPATH=/home/ubuntu/BigDataProject

source ~/.profile
cat ~/.profile

sudo nano ~/.bashrc

export SPARK_HOME=/usr/local/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3.6
export PYSPARK_SUBMIT_ARGS="--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell"
export PYTHONPATH=/home/ubuntu/BigDataProject

source ~/.bashrc
cat ~/.bashrc

ctrl+d
ssh ubuntu@192.168.254.187 (passphrase: pass)
printenv

cd ~
git clone https://github.com/KypY12/BigDataProject.git
cd BigDataProject
ls -al

cd ~
pip3 install --user kaggle
kaggle
cd .kaggle/
ls -al
nano kaggle.json
cat kaggle.json

kaggle datasets list -s arxiv
cd BigDataProject/
kaggle datasets download -d Cornell-University/arxiv

unzip arxiv.zip
ls -al

hadoop fs -ls /
hadoop fs -mkdir -p /user/data/original
hadoop fs -ls /user/data/
hadoop fs -put arxiv-metadata-oai-snapshot.json /user/data/original/arxiv-metadata-oai-snapshot.json
hadoop fs -ls /user/data/original

pip3 install --user pandas
pip3 install --user pyspark

cd processing
ls -al
python3 preprocess.py


########################################################################################################################
# Comenzi instalare pe Linux personal

# Instalare python 3

    # Verificare Versiune Python
        python --version
        python3 --version

# Instalare Java

    # Verificare Versiune Java
        java -version

# Instalare Scala
    wget https://downloads.lightbend.com/scala/2.12.15/scala-2.12.15.deb
    sudo dpkg -i scala-2.12.15.deb

   # Verificare Versiune Scala
    scala -version

# Instalare Spark

tar -xvzf spark-3.2.0-bin-hadoop3.2.tgz
sudo mv spark-3.2.0-bin-hadoop3.2 /opt/spark

pip3 install --user py4j


pyspark --version

# Verificare

pyspark --packages graphframes:graphframes:0.8.2-spark3.2-s_2.12
ls /root/.ivy2/jars
ls /home/cristian_adam/.ivy2/jars
ls -l /home/cristian_adam/.ivy2/jars
cd /opt/spark/jars/
cp /home/cristian_adam/.ivy2/jars/* .

# Setare Variabile System Environment

echo "export SPARK_HOME=/opt/spark" >> ~/.profile
echo "export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin" >> ~/.profile
echo "export PYSPARK_PYTHON=/usr/bin/python3" >> ~/.profile

sudo nano ~/.profile
source ~/.profile
sudo nano ~/.bashrc
source ~/.bashrc

export SPARK_HOME=/opt/spark
export PATH=$PATH:$SPARK_HOME/bin:$SPARK_HOME/sbin
export PYSPARK_PYTHON=/usr/bin/python3.6
export PYSPARK_SUBMIT_ARGS="--packages graphframes:graphframes:0.8.2-spark3.2-s_2.12 pyspark-shell"


spark-submit -version
spark-submit --version


